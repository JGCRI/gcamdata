# driver.R


TEMP_DATA_INJECT <- "temp-data-inject/"

#' run_chunk
#'
#' @param chunk Chunk name, character
#' @param all_data Data required by chunk
#' @return Data generated by chunk
#' @details Putting this \code{do.call} into this one-line
#' function lets us mock it when testing.
run_chunk <- function(chunk, all_data) {
  do.call(chunk, list(driver.MAKE, all_data))
}


#' check_chunk_outputs
#'
#' Checks chunk outputs for a variety of problems: correct structure,
#' correct attributes attached, matches promised outputs. Generates
#' warnings and/or errors if any deviance.
#'
#' @param chunk Chunk name, character
#' @param chunk_data Data produced by chunk
#' @param chunk_inputs Names of chunk inputs, character
#' @param promised_outputs Names of chunk's promised outputs, character
#' @param outputs_xml Logical vector: are outputs XML?
check_chunk_outputs <- function(chunk, chunk_data, chunk_inputs, promised_outputs, outputs_xml) {
  assert_that(is_data_list(chunk_data))

  # Check that the chunk has provided required data for all objects
  empty_precursors <- TRUE
  for(obj in names(chunk_data)) {
    # Chunks have to returns tibbles, unless they're tagged as being XML
    if(!outputs_xml[which(obj == promised_outputs)]) {
      assert_that(tibble::is.tibble(chunk_data[[obj]]))
      assert_that(! FLAG_XML %in% get_flags(chunk_data[[obj]]))  # TODO: need to update tests for this!

      # Make sure objects have required attributes
      for(at in c(ATTR_TITLE, ATTR_UNITS, ATTR_COMMENTS, ATTR_LEGACY_NAME)) {
        if(is.null(attr(chunk_data[[obj]], at))) {
          warning("No '", at, "' attached to ", obj, " - chunk ", chunk)
        }
      }
    } else {
      chunk_data[[obj]] <- add_flags(chunk_data[[obj]], FLAG_XML)  # TODO: udpate tests!
    }
    # Data precursors should all appear in input list
    pc <- attr(chunk_data[[obj]], ATTR_PRECURSORS)
    empty_precursors <- empty_precursors & is.null(pc)
    matches <- pc %in% c(chunk_inputs, promised_outputs)
    if(!all(matches)) {
      stop("Some precursors for '", obj, "' aren't inputs - chunk ", chunk)
    }
    if(obj %in% pc) {
      stop("Precursors for '", obj, "' include itself - chunk ", chunk)
    }
  }

  # If chunk has inputs, some output should have a precursor
  if(empty_precursors & length(chunk_inputs)) {
    stop("No output precursors, but there are inputs - chunk ", chunk)
  }
  # Chunk should have returned EXACTLY what it promised
  if(!identical(sort(names(chunk_data)), sort(promised_outputs))) {
    stop("Chunk ", chunk, "is not returning what it promised!")
  }
}


#' driver
#'
#' Run the entire data system.
#'
#' @param all_data Data to be pre-loaded into data system
#' @param write_outputs Write all chunk outputs to disk?
#' @param quiet Suppress output?
#' @param outdir Location to write output data.  (Ignored if \code{write_outputs} is \code{FALSE}.)
#' @return A list of all built data.
#' @details The driver loads any necessary data from input files,
#' runs all code chunks in an order dictated by their dependencies,
#' does error-checking, and writes outputs. For more details, see
#' the relevant wiki page at \url{ https://github.com/bpbond/gcamdata/wiki/Driver}.
#' @importFrom magrittr "%>%"
#' @importFrom assertthat assert_that
#' @export
#' @author BBL
driver <- function(all_data = empty_data(), write_outputs = TRUE, quiet = FALSE, outdir = OUTPUTS_DIR) {
  assert_that(is.logical(write_outputs))

  chunklist <- find_chunks()
  if(!quiet) cat("Found", nrow(chunklist), "chunks\n")

  chunkinputs <- chunk_inputs(chunklist$name)
  if(!quiet) cat("Found", nrow(chunkinputs), "chunk data requirements\n")
  chunkoutputs <- chunk_outputs(chunklist$name)
  if(!quiet) cat("Found", nrow(chunkoutputs), "chunk data products\n")

  warn_data_injects()

  # Outputs should all be unique
  dupes <- duplicated(chunkoutputs$output)
  if(any(dupes)) {
    stop("Outputs appear multiple times: ", chunkoutputs$output[dupes])
  }

  # If there are any unaccounted for input requirements,
  # try to load them from csv files
  unfound_inputs <- filter(chunkinputs, !input %in% chunkoutputs$output)
  if(nrow(unfound_inputs)) {

    # These should all be marked as 'from_file'
    ff <- filter(unfound_inputs, !from_file)
    if(nrow(ff)) {
      stop("Unfound inputs not marked as from file: ", paste(ff$input, collapse = ", "),
           " in ", paste(unique(ff$name), collapse = ", "))
    }

    if(!quiet) cat(nrow(unfound_inputs), "chunk data input(s) not accounted for\n")
    csv_data <- load_csv_files(unfound_inputs$input, unfound_inputs$optional, quiet = TRUE)
    all_data <- add_data(csv_data, all_data)
  }

  chunks_to_run <- chunklist$name
  while(length(chunks_to_run)) {
    nchunks <- length(chunks_to_run)

    # Loop through all chunks and see who can run (i.e. all dependencies are available)
    for(chunk in chunks_to_run) {
      if(!quiet) print(chunk)

      input_names <- dplyr::filter(chunkinputs, name == chunk)$input
      if(!all(input_names %in% names(all_data))) {
        if(!quiet) print("- data not available yet")
        next  # chunk's inputs are not all available
      }

      # Order chunk to build its data
      time1 <- Sys.time()
      chunk_data <- run_chunk(chunk, all_data[input_names])
      # Disabled this code because `capture.output` causes problems in debugging
      #out <- capture.output(chunk_data <- run_chunk(chunk, all_data[input_names]))
      #if(!quiet & length(out)) cat(out, sep = "\n")
      tdiff <- as.numeric(difftime(Sys.time(), time1, units = "secs"))
      if(!quiet) print(paste("- make", format(round(tdiff, 2), nsmall = 2)))

      check_chunk_outputs(chunk, chunk_data, input_names,
                          promised_outputs = subset(chunkoutputs, name == chunk)$output,
                          outputs_xml = subset(chunkoutputs, name == chunk)$to_xml)

      # Add this chunk's data to the global data store
      all_data <- add_data(chunk_data, all_data)

      # Remove the current chunk from the to-run list
      chunks_to_run <- chunks_to_run[chunks_to_run != chunk]
    } # for

    # We have to be able to run >=1 chunk every loop iteration
    if(length(chunks_to_run) == nchunks) {
      stop("No chunks were run--we are stuck")
    }
  } # while

  if(!quiet) cat(length(all_data), "data frames generated\n")

  if(write_outputs) {
    if(!quiet) cat("Writing chunk data...\n")
    save_chunkdata(all_data, outputs_dir = outdir)
  }

  if(!quiet) cat("All done.\n")
  invisible(all_data)
}


#' warn_data_injects
#'
#' Check whether chunks are using any temporary (old data system data) 'injected' inputs.
#'
#' @return Number of temporary data objects being used inappropriately.
warn_data_injects <- function() {

  # Are any chunks are using temp-data-inject data that are also available to them through the data system?
  ci <- chunk_inputs(find_chunks(include_disabled = FALSE)$name)
  chunk_outputs(find_chunks(include_disabled = FALSE)$name) %>%
    rename(upstream_chunk = name) ->
    co

  # Look for TEMP_DATA_INJECT pattern in the chunk input list
  ci[grep(TEMP_DATA_INJECT, ci$input),] %>%
    mutate(base_input = basename(input)) %>%
    # Look for any tdi inputs that appear in the enabled chunks' outputs
    filter(base_input %in% co$output) %>%
    left_join(select(co, upstream_chunk, output), by = c("base_input" = "output")) ->
    ci_tdi

  # Print messages
  for(i in seq_len(nrow(ci_tdi))) {
    message("NOTE: chunk ", ci_tdi$name[i], " reads `", ci_tdi$input[i], "`\n\tbut this is available from ", ci_tdi$upstream_chunk[i])
  }
  nrow(ci_tdi)
}
